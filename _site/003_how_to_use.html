<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/supercomputing-for-ai-book/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/supercomputing-for-ai-book/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(3)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(3) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(2) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(3) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list { display: block; } </style> <script src="/supercomputing-for-ai-book/assets/js/vendor/lunr.min.js"></script> <script src="/supercomputing-for-ai-book/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/supercomputing-for-ai-book/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>How to Use This Book | Supercomputing for AI</title> <meta name="generator" content="Jekyll v4.4.1" /> <meta property="og:title" content="How to Use This Book" /> <meta name="author" content="Jordi Torres" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Foundations, Architectures, and Scaling Deep Learning Workloads" /> <meta property="og:description" content="Foundations, Architectures, and Scaling Deep Learning Workloads" /> <link rel="canonical" href="http://localhost:4000/supercomputing-for-ai-book/003_how_to_use.html" /> <meta property="og:url" content="http://localhost:4000/supercomputing-for-ai-book/003_how_to_use.html" /> <meta property="og:site_name" content="Supercomputing for AI" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="How to Use This Book" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Jordi Torres"},"description":"Foundations, Architectures, and Scaling Deep Learning Workloads","headline":"How to Use This Book","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/supercomputing-for-ai-book/images/Supercomputing_for_AI_BookCover.jpg"},"name":"Jordi Torres"},"url":"http://localhost:4000/supercomputing-for-ai-book/003_how_to_use.html"}</script> <!-- End Jekyll SEO tag --> <style> /* 1. Agrandar la Portada (Logo) */ .site-brand img { max-height: none !important; width: 100% !important; max-width: 200px !important; margin-bottom: 5px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); } /* Ocultar el título de texto de la barra lateral (ya sale en la foto) */ .site-brand .site-title { display: none; } /* 2. Ajustar títulos H4 del contenido */ .main-content h4 { font-size: 1.1em; font-weight: bold; color: #505050; margin-top: 20px; } /* 3. Ajustar imágenes del contenido */ .main-content img { display: block; margin: 0 auto; max-width: 100%; } </style> <script> document.addEventListener("DOMContentLoaded", function() { // Definimos el texto que quieres mostrar var textoReferencia = ` <div style="font-size:0.85em; color:#333; line-height:1.4; margin-bottom:20px;"> <br> <b>Reference:</b><br> Jordi Torres, <i>Supercomputing for Artificial Intelligence</i>, WATCH THIS SPACE Book Series, 2025.<br> <span style="font-size:0.9em; color:#666;">ISBN 979-831932835-9</span> <br><br> <a href="https://www.amazon.com/dp/B0DJCMK8W1" target="_blank" style="text-decoration:underline; color:#0366d6;">Buy on Amazon</a> </div> `; // Buscamos la zona del logo e inyectamos el texto justo después var logoArea = document.querySelector('.site-brand'); if(logoArea) { logoArea.insertAdjacentHTML('beforeend', textoReferencia); } }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <header class="side-bar"> <div class="site-header"> <a href="/supercomputing-for-ai-book/" class="site-title lh-tight"> <div class="site-logo" role="img" aria-label="Supercomputing for AI"></div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Menu" aria-expanded="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="Context and Reader’s Guide submenu" aria-expanded="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supercomputing-for-ai-book/000_Part_context.html" class="nav-list-link">Context and Reader’s Guide</a><ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/001_content.html" class="nav-list-link">Book overview and Table of Contents (PDF)</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/002_preface.html" class="nav-list-link">Preface</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/003_how_to_use.html" class="nav-list-link">How to Use This Book</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/004_FourAxis.html" class="nav-list-link">The Four Axes of the Book</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/005_Foundational-Performance-Principles.html" class="nav-list-link">Foundational Performance Principles</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/006_Technologies.html" class="nav-list-link">Technologies and Navigation aids</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/007_EditorialNotes.html" class="nav-list-link">Editorial Notes</a></li></ul></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/010_acknowledgments.html" class="nav-list-link">Acknowledgments</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/100_Part_I.html" class="nav-list-link">Part I — The Infrastructure Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/200_Part_II.html" class="nav-list-link">Part II — The Parallel Execution Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/300_Part_III.html" class="nav-list-link">Part III — The Intelligence Abstraction Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/400_Part_IV.html" class="nav-list-link">Part IV — The Scalability Layer</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="Part V — The Language Abstraction Layer submenu" aria-expanded="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supercomputing-for-ai-book/500_Part_V.html" class="nav-list-link">Part V — The Language Abstraction Layer</a><ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/ch15.html" class="nav-list-link">15. Exploring Optimization and Scaling of LLMs</a></li></ul></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/600_Beyond_the_Layers.html" class="nav-list-link">Beyond the Layers</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/700_Epilogue.html" class="nav-list-link">Epilogue</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/800_Appendices.html" class="nav-list-link">Appendices</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/900_colophon.html" class="nav-list-link">Colophon</a></li></ul> </nav> <div class="d-md-block d-none site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </div> </header> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Supercomputing for AI" autocomplete="off"> <label for="search-input" class="search-label"> <span class="sr-only">Search Supercomputing for AI</span> <svg viewBox="0 0 24 24" class="search-icon" aria-hidden="true"><use xlink:href="#svg-search"></use></svg> </label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/supercomputing-for-ai-book/000_Part_context.html">Context and Reader’s Guide</a></li> <li class="breadcrumb-nav-list-item"><span>How to Use This Book</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="how-to-use-this-book"> <a href="#how-to-use-this-book" class="anchor-heading" aria-labelledby="how-to-use-this-book"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How to Use This Book </h1> <h3 id="about-this-book"> <a href="#about-this-book" class="anchor-heading" aria-labelledby="about-this-book"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> About This Book </h3> <p>This book was written with a clear intent: to help readers understand how modern artificial intelligence workloads—particularly large-scale training—are executed, scaled, and optimized on supercomputing infrastructures. Its focus is not on proposing new algorithms or surveying model architectures, but on explaining how existing AI methods interact with hardware, system software, runtimes, and distributed execution environments.</p> <p>The subtitle of this book—Foundations, Architectures, and Scaling Deep Learning Workloads—is a deliberate statement of scope and method. “Foundations” refers to the performance principles and reasoning habits used throughout the book to interpret measurements and avoid misleading conclusions. “Architectures” covers the hardware–software stack that makes large-scale training possible: compute nodes, system software, runtimes, and parallel execution models. “Scaling” focuses on making deep learning training workflows run efficiently across multiple GPUs and nodes, connecting high-level frameworks to the underlying execution and communication mechanisms.</p> <p>The material originated from several university courses taught at the Universitat Politècnica de Catalunya (UPC), each with different scopes, depths, and prerequisites. As a result, the book was deliberately designed to support readers with diverse backgrounds and objectives. Rather than assuming a single, linear learning path, it provides multiple entry points and flexible routes through the content.</p> <p>Some readers may approach the book from a high performance computing background and wish to understand how deep learning and large language models are trained at scale. Others may come from an AI or data science perspective and want to understand what happens beneath high-level frameworks when training is distributed across GPUs and nodes. This book is intended to support both perspectives, and to help bridge the conceptual gap between them.</p> <p>This book is intended for readers who want a system-oriented understanding of how AI training runs in practice, including:</p> <ul> <li> <p>Master’s and advanced undergraduate students seeking a practical view of AI workloads on modern supercomputing platforms;</p> </li> <li> <p>Researchers interested in performance, scalability, and distributed execution of large-scale training;</p> </li> <li> <p>Engineers and data scientists using deep learning frameworks who want to understand what happens beneath high-level APIs;</p> </li> <li> <p>HPC practitioners and system architects looking to connect AI requirements with infrastructure design choices;</p> </li> <li> <p>Instructors building reusable laboratory assignments and reproducible experiments for courses at the intersection of HPC and AI.</p> </li> </ul> <p>The emphasis throughout is on training workloads executed on supercomputing platforms. Inference, deployment, and edge scenarios are acknowledged where relevant, but they are not treated as primary optimization targets. This choice reflects the book’s central thesis: the most demanding and instructive challenges arise during large-scale training, where compute, memory, communication, and coordination costs interact most strongly.</p> <h3 id="how-to-read-this-book"> <a href="#how-to-read-this-book" class="anchor-heading" aria-labelledby="how-to-read-this-book"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How to Read This Book </h3> <p>This book can be read in more than one way, and no single reading strategy is assumed.</p> <p>It can be read as a conceptual and theoretical resource, focusing on architecture, execution models, and performance reasoning without executing any code. Readers following this approach may concentrate on the explanatory text, figures, and performance discussions, using the tasks as illustrative examples rather than as mandatory exercises.</p> <p>Alternatively, it can be used as a hands-on guide, where understanding is built primarily through execution and experimentation. In this mode, readers are encouraged to run the tasks, modify parameters, observe performance behavior, and relate the results back to the conceptual models presented in the text.</p> <p>Selective reading is not only acceptable; it is intentional. The book is structured around abstraction layers and self-contained chapters, making it possible to focus on specific parts without reading everything in sequence. For example:</p> <ul> <li> <p>Readers with a strong supercomputing background may skim Parts I and II and jump directly to Parts III, IV or V.</p> </li> <li> <p>Readers already familiar with deep learning frameworks may skim Part III and focus on distributed training and scalability.</p> </li> <li> <p>Readers primarily interested in large language models may concentrate on Parts IV and V, using earlier chapters as reference material when needed.</p> </li> </ul> <p>Throughout the book, cross-references and recurring figures are used to maintain coherence across these different paths. The goal is not exhaustive coverage, but the development of a solid mental model that can be applied consistently across scales and technologies.</p> <h3 id="how-to-use-this-book-in-practical-laboratory-courses"> <a href="#how-to-use-this-book-in-practical-laboratory-courses" class="anchor-heading" aria-labelledby="how-to-use-this-book-in-practical-laboratory-courses"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How to Use This Book in Practical Laboratory Courses </h3> <p>A defining characteristic of this book is its task-based structure. Practical tasks are intentionally fine-grained, self-contained, and designed to be combined flexibly. They are not meant to be executed all at once, nor do they form a single mandatory sequence.</p> <p>In instructor-led courses, laboratory assignments are typically constructed by selecting a subset of tasks aligned with specific learning objectives, available infrastructure, and time constraints. This approach allows the same book to support courses with very different profiles—for example, introductory HPC courses with an AI focus, advanced courses on distributed deep learning, or specialized seminars on large language models.</p> <p>Independent readers are encouraged to adopt a similar strategy. Tasks should be treated as building blocks rather than as a checklist. Some tasks are exploratory and introductory, others consolidate core concepts, and a smaller number are intended for deeper experimentation and performance analysis. Readers may return to tasks multiple times as their understanding evolves.</p> <p>Reproducibility is a central concern in the design of these tasks. Wherever possible, experiments are grounded in concrete execution environments, explicit job scripts, and well-defined software stacks. Examples are aligned with real systems—such as MareNostrum 5 supercomputer at the Barcelona Supercomputing Center—or with accessible platforms like Google Colab, allowing readers to move between environments while preserving the same execution model.</p> <p>This modular, task-oriented approach reflects a pedagogical belief that depth of understanding is achieved through carefully chosen practical experiences, not through exhaustive coverage. The book is therefore intended to be reused, adapted, and revisited, both in formal courses and in independent study, as technologies and workloads continue to evolve.</p> <h3 id="typographical-conventions-used-in-this-book"> <a href="#typographical-conventions-used-in-this-book" class="anchor-heading" aria-labelledby="typographical-conventions-used-in-this-book"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Typographical Conventions Used in This Book </h3> <p>Throughout this book, we use a set of typographical conventions to improve readability and clarity. These are summarized below for your reference:</p> <ul> <li> <p>Text in Courier is used to indicate variable names in code, file names, URLs, and similar elements.</p> </li> <li> <p> Text in <em>italics</em> is used to highlight important concepts within the book’s content, often when they are introduced for the first time.</p> </li> <li> <p>Code blocks are displayed using a monospaced font on a gray background, as shown below:</p> </li> </ul> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;stdio.h&gt;

int main(){

    printf("Hello world!\n");

}
</code></pre></div> </div> </blockquote> <ul> <li>Highlighted lines within code blocks—those that are referenced in the main text—appear in bold monospaced font on the same gray background:</li> </ul> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;stdio.h&gt;

int main(){

    printf("Hello world!\n");

}
</code></pre></div> </div> </blockquote> <ul> <li>Command-line commands are shown in a monospaced font on a gray background, prefixed with a $ symbol to indicate they are entered in a terminal session:</li> </ul> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ module load intel

$ icx hello.c -o hello
</code></pre></div> </div> </blockquote> <ul> <li>Standard output is shown in Courier New font:</li> </ul> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./hello
</code></pre></div> </div> <p>Hello world!</p> </blockquote> <h4 id="a-note-on-the-figures"> <a href="#a-note-on-the-figures" class="anchor-heading" aria-labelledby="a-note-on-the-figures"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Note on the Figures </h4> <p>Some figures in this book—particularly in the early chapters—are intentionally hand-drawn. They originate from the first editions of the material (in 2016) and have been deliberately preserved.</p> <p>This is not a limitation, nor an oversight. It is a conscious editorial choice and, in part, a homage to the origins of this book and to a way of teaching and thinking about supercomputing that has proven remarkably durable.</p> <p>More than ten years later, these figures still convey the same ideas with clarity. That persistence is precisely why they remain.</p> </main> <hr> <footer> <div class="d-md-none mt-4 fs-2"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
