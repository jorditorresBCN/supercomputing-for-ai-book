<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/supercomputing-for-ai-book/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/supercomputing-for-ai-book/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(5)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(5) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(2) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(5) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list > li.nav-list-item:nth-child(5) > ul.nav-list { display: block; } </style> <script src="/supercomputing-for-ai-book/assets/js/vendor/lunr.min.js"></script> <script src="/supercomputing-for-ai-book/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/supercomputing-for-ai-book/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Foundational Performance Principles | Supercomputing for AI</title> <meta name="generator" content="Jekyll v4.4.1" /> <meta property="og:title" content="Foundational Performance Principles" /> <meta name="author" content="Jordi Torres" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Foundations, Architectures, and Scaling Deep Learning Workloads" /> <meta property="og:description" content="Foundations, Architectures, and Scaling Deep Learning Workloads" /> <link rel="canonical" href="http://localhost:4000/supercomputing-for-ai-book/005_Foundational-Performance-Principles.html" /> <meta property="og:url" content="http://localhost:4000/supercomputing-for-ai-book/005_Foundational-Performance-Principles.html" /> <meta property="og:site_name" content="Supercomputing for AI" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Foundational Performance Principles" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Jordi Torres"},"description":"Foundations, Architectures, and Scaling Deep Learning Workloads","headline":"Foundational Performance Principles","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/supercomputing-for-ai-book/images/Supercomputing_for_AI_BookCover.jpg"},"name":"Jordi Torres"},"url":"http://localhost:4000/supercomputing-for-ai-book/005_Foundational-Performance-Principles.html"}</script> <!-- End Jekyll SEO tag --> <style> /* 1. Agrandar la Portada (Logo) */ .site-brand img { max-height: none !important; width: 100% !important; max-width: 200px !important; margin-bottom: 5px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); } /* Ocultar el título de texto de la barra lateral (ya sale en la foto) */ .site-brand .site-title { display: none; } /* 2. Ajustar títulos H4 del contenido */ .main-content h4 { font-size: 1.1em; font-weight: bold; color: #505050; margin-top: 20px; } /* 3. Ajustar imágenes del contenido */ .main-content img { display: block; margin: 0 auto; max-width: 100%; } </style> <script> document.addEventListener("DOMContentLoaded", function() { // Definimos el texto que quieres mostrar var textoReferencia = ` <div style="font-size:0.85em; color:#333; line-height:1.4; margin-bottom:20px;"> <br> <b>Reference:</b><br> Jordi Torres, <i>Supercomputing for Artificial Intelligence</i>, WATCH THIS SPACE Book Series, 2025.<br> <span style="font-size:0.9em; color:#666;">ISBN 979-831932835-9</span> <br><br> <a href="https://www.amazon.com/dp/B0DJCMK8W1" target="_blank" style="text-decoration:underline; color:#0366d6;">Buy on Amazon</a> </div> `; // Buscamos la zona del logo e inyectamos el texto justo después var logoArea = document.querySelector('.site-brand'); if(logoArea) { logoArea.insertAdjacentHTML('beforeend', textoReferencia); } }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <header class="side-bar"> <div class="site-header"> <a href="/supercomputing-for-ai-book/" class="site-title lh-tight"> <div class="site-logo" role="img" aria-label="Supercomputing for AI"></div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Menu" aria-expanded="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="Context and Reader’s Guide submenu" aria-expanded="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supercomputing-for-ai-book/000_Part_context.html" class="nav-list-link">Context and Reader’s Guide</a><ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/001_content.html" class="nav-list-link">Book overview and Table of Contents (PDF)</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/002_preface.html" class="nav-list-link">Preface</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/003_how_to_use.html" class="nav-list-link">How to Use This Book</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/004_FourAxis.html" class="nav-list-link">The Four Axes of the Book</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/005_Foundational-Performance-Principles.html" class="nav-list-link">Foundational Performance Principles</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/006_Technologies.html" class="nav-list-link">Technologies and Navigation aids</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/007_EditorialNotes.html" class="nav-list-link">Editorial Notes</a></li></ul></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/010_acknowledgments.html" class="nav-list-link">Acknowledgments</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/100_Part_I.html" class="nav-list-link">Part I — The Infrastructure Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/200_Part_II.html" class="nav-list-link">Part II — The Parallel Execution Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/300_Part_III.html" class="nav-list-link">Part III — The Intelligence Abstraction Layer</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/400_Part_IV.html" class="nav-list-link">Part IV — The Scalability Layer</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="Part V — The Language Abstraction Layer submenu" aria-expanded="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supercomputing-for-ai-book/500_Part_V.html" class="nav-list-link">Part V — The Language Abstraction Layer</a><ul class="nav-list"><li class="nav-list-item"><a href="/supercomputing-for-ai-book/ch15.html" class="nav-list-link">15. Exploring Optimization and Scaling of LLMs</a></li></ul></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/600_Beyond_the_Layers.html" class="nav-list-link">Beyond the Layers</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/700_Epilogue.html" class="nav-list-link">Epilogue</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/800_Appendices.html" class="nav-list-link">Appendices</a></li><li class="nav-list-item"><a href="/supercomputing-for-ai-book/900_colophon.html" class="nav-list-link">Colophon</a></li></ul> </nav> <div class="d-md-block d-none site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </div> </header> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Supercomputing for AI" autocomplete="off"> <label for="search-input" class="search-label"> <span class="sr-only">Search Supercomputing for AI</span> <svg viewBox="0 0 24 24" class="search-icon" aria-hidden="true"><use xlink:href="#svg-search"></use></svg> </label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/supercomputing-for-ai-book/000_Part_context.html">Context and Reader’s Guide</a></li> <li class="breadcrumb-nav-list-item"><span>Foundational Performance Principles</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="foundational-performance-principles"> <a href="#foundational-performance-principles" class="anchor-heading" aria-labelledby="foundational-performance-principles"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Foundational Performance Principles </h1> <ul id="markdown-toc"> <li><a href="#foundational-performance-principles" id="markdown-toc-foundational-performance-principles">Foundational Performance Principles</a> <ul> <li><a href="#the-four-diagnostic-lenses" id="markdown-toc-the-four-diagnostic-lenses">The Four Diagnostic Lenses</a> <ul> <li><a href="#amortization-of-overheads" id="markdown-toc-amortization-of-overheads">Amortization of Overheads</a></li> <li><a href="#hardwaresoftware-co-design" id="markdown-toc-hardwaresoftware-co-design">Hardware–Software Co-Design</a></li> <li><a href="#balanced-pipelines" id="markdown-toc-balanced-pipelines">Balanced Pipelines</a></li> <li><a href="#scale-must-serve-purpose" id="markdown-toc-scale-must-serve-purpose">Scale Must Serve Purpose</a></li> </ul> </li> </ul> </li> </ul> <h3 id="the-four-diagnostic-lenses"> <a href="#the-four-diagnostic-lenses" class="anchor-heading" aria-labelledby="the-four-diagnostic-lenses"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Four Diagnostic Lenses </h3> <p>Throughout this book, performance is analyzed using four Foundational Performance Principles. These principles are best understood as <em>diagnostic lenses</em> rather than optimization rules.</p> <p>In modern AI workflows, correctness is an increasingly weak signal. A training job that converges, a distributed run that completes, or a pipeline that produces results may still be fundamentally inefficient, uneconomic, or poorly scaled. These four principles are introduced to make such failure modes visible. Their purpose is not to accelerate systems blindly, but to reveal when apparent success hides structural inefficiency.</p> <p>They are not intended to be applied sequentially, nor do they form a hierarchy. Figure 4 summarizes them as four complementary diagnostic lenses. In real systems, all four are active simultaneously. Each lens highlights a different constraint that shapes observed performance behavior.</p> <h4 id="amortization-of-overheads"> <a href="#amortization-of-overheads" class="anchor-heading" aria-labelledby="amortization-of-overheads"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Amortization of Overheads </h4> <p>This principle explains why fixed costs—such as kernel launches, memory allocations, synchronization barriers, or process coordination—must be spread over enough useful work to become negligible.</p> <p>It provides the intuition behind practices such as operating on sufficiently large matrices, choosing appropriate batch sizes, or avoiding excessively fine-grained parallelism. When overheads dominate useful computation, even powerful hardware will appear underutilized.</p> <p>In practice, this principle explains why “it runs” is not evidence that it scales. AI-generated pipelines often produce correct execution flows that are dominated by fixed overheads—kernel launches, synchronization points, communication setup, or framework-level coordination. Apparent correctness can therefore mask pathological inefficiency.</p> <h4 id="hardwaresoftware-co-design"> <a href="#hardwaresoftware-co-design" class="anchor-heading" aria-labelledby="hardwaresoftware-co-design"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hardware–Software Co-Design </h4> <p>This principle emphasizes that modern hardware capabilities only translate into performance when the software stack is designed to exploit them.</p> <p>High-end GPUs, fast interconnects, tensor cores, or advanced memory hierarchies offer no intrinsic benefit if runtimes, libraries, and frameworks fail to expose or orchestrate their use. Performance emerges from the <em>joint</em> design of hardware and software, not from either in isolation.</p> <p>When code is generated without awareness of the underlying hardware, mismatches between software abstractions and physical execution units become invisible but costly. Generic framework-level solutions may ignore memory hierarchies, interconnect topology, or accelerator-specific execution models. In such cases, abstraction hides the cost—but hardware still pays it.</p> <h4 id="balanced-pipelines"> <a href="#balanced-pipelines" class="anchor-heading" aria-labelledby="balanced-pipelines"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Balanced Pipelines </h4> <p>This principle states that overall performance is limited by the slowest stage in the execution pipeline.</p> <p>In practice, many performance problems are not solved by acquiring faster accelerators, but by eliminating imbalances—such as situations where GPUs wait for data loading, preprocessing, or CPU-side work. In such cases, software engineering and pipeline design matter more than raw compute capability.</p> <p>AI-assisted development tends to optimize locally: faster kernels, larger batch sizes, deeper models. This principle exists to reveal why such local improvements frequently fail at the system level, producing idle hardware, stalled execution, and wasted resources. Local brilliance does not imply global performance.</p> <h4 id="scale-must-serve-purpose"> <a href="#scale-must-serve-purpose" class="anchor-heading" aria-labelledby="scale-must-serve-purpose"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Scale Must Serve Purpose </h4> <p>This principle challenges the assumption that scaling is inherently beneficial.</p> <p>Adding more GPUs or nodes does not automatically improve outcomes if communication overheads, efficiency losses, or costs outweigh the gains. Purpose-driven scaling explicitly connects performance, efficiency, and cost, framing scaling decisions in terms of objectives rather than maximum hardware usage.</p> <p>In modern AI systems, the cost of a logical bug is often negligible. The cost of a poor scaling decision can be orders of magnitude larger. This principle exists to prevent the most expensive class of errors in contemporary AI workloads: scaling without purpose, measurement, or economic justification.</p> <p>Together, these four lenses provide a compact yet expressive framework for reasoning about performance across all levels of the AI training stack.</p> <p><img src="images/04_structure/media/image4.png" style="width:5.16912in;height:1.9783in" alt="A close-up of a sign AI-generated content may be incorrect." /></p> <p><em>Figure 4 — The four Foundational Performance Principles presented as diagnostic lenses.</em></p> <p>The Foundational Performance Principles are not introduced all at once, nor are they presented upfront as abstract theory. Instead, they are deliberately staged throughout the book, following a pedagogical progression aligned with the reader’s growing technical context.</p> <p>Early chapters expose the reader to concrete performance phenomena—such as underutilized hardware, unexpected slowdowns, or limited scalability—without immediately naming the underlying principles. This allows intuition to form through observation and experimentation.</p> <p>As the necessary architectural and execution context becomes available, each principle is introduced explicitly, formalized, and connected to concrete examples. At that point, the reader can recognize recurring patterns that were previously encountered implicitly.</p> <p>This approach serves two goals:</p> <ul> <li> <p>it avoids premature abstraction before the reader has sufficient grounding,</p> </li> <li> <p>and it reinforces the idea that the same principles apply repeatedly across abstraction layers.</p> </li> </ul> <p>As the book progresses, the principles reappear in increasingly complex settings: from GPU kernels, to data pipelines, to distributed training, and finally to large-scale LLM workloads. What changes is not the principle itself, but the scale and richness of the systems to which it is applied.</p> <p>Readers are encouraged to revisit these principles continuously. Recognizing familiar performance behaviors in new contexts is a central learning objective of the book—and a key step toward developing true system-level intuition.</p> </main> <hr> <footer> <div class="d-md-none mt-4 fs-2"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
